{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Torch ##\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "## SHAP ##\n",
    "import shap \n",
    "\n",
    "## Utils ##\n",
    "from deeputils.DeepLearningArchitecture import DeepLearningArchitecture\n",
    "from deeputils.feature_name_map import feature_name_dict\n",
    "from deeputils.SHAP_Features import model_xai\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Use best Device (CUDA vs CPU) ###\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "## Print Device Properties ##\n",
    "if device == torch.device('cuda'):\n",
    "    print( torch.cuda.get_device_properties( device ) )\n",
    "\n",
    "### Seed ###\n",
    "random_state = 1234\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "## CUDNN ##\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skip Completed Models ##\n",
    "skip_complete=True\n",
    "problem_id = 20\n",
    "time_len = '1year'\n",
    "loss_type = 'weighted_loss'\n",
    "\n",
    "## Folder paths ##\n",
    "raw_train_data = pd.read_csv('/home/wenqi/GL-SMART-aim2/pre-processed-data/pp_data_preop_{}.csv'.format(time_len))\n",
    "feature_list = raw_train_data.columns[:172]\n",
    "x = raw_train_data[feature_list]\n",
    "x = x.drop('PID', axis='columns')\n",
    "focus_id = problem_id + 201\n",
    "focus_label = raw_train_data.columns[focus_id]\n",
    "y = raw_train_data[focus_label]\n",
    "criteria = [4, 4, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 5, 5, 4, 5, 4, 5, 4, 4, 5]\n",
    "c = criteria[problem_id]\n",
    "if c == 4:\n",
    "    y[y<4] = 0\n",
    "    y[y>=4] = 1\n",
    "elif c == 5:\n",
    "    y[y<4.5] = 0\n",
    "    y[y>=4.5] = 1\n",
    "results_folder = '/home/wenqi/GL-SMART-aim2/{}/deep-models-{}/{}/results/'.format(loss_type, time_len, focus_label)\n",
    "results_file = '/home/wenqi/GL-SMART-aim2/{}/deep-models-{}/{}/results/Validation-80Trained_HPTuneSpreadsheet.csv'.format(loss_type, time_len, focus_label)\n",
    "models_folder='/home/wenqi/GL-SMART-aim2/{}/deep-models-{}/{}/'.format(loss_type, time_len, focus_label)\n",
    "figures_folder='/home/wenqi/GL-SMART-aim2/Figures/FeatureRanks/'\n",
    "\n",
    "## File with Deep Learning models HP Tuning Information ##\n",
    "hptune_csv = results_file\n",
    "hptune_df = pd.read_csv(hptune_csv)\n",
    "\n",
    "## Outcome variable ##\n",
    "outcome_column='death90+vent'\n",
    "## Feature Ranks (output) ##\n",
    "feature_ranks_path = results_folder+'FeatureRanks_All.csv'\n",
    "\n",
    "## SHAP Variables ##\n",
    "top_n_features = 20\n",
    "\n",
    "### Deep Learning Model Classifiers ###\n",
    "model_type_list = [\n",
    "    'relu',\n",
    "    # 'softmax',\n",
    "    # 'sigmoid',\n",
    "    # 'gumbel_softmax',\n",
    "]\n",
    "\n",
    "## Dictionary with Feature Ranks ##\n",
    "f_rankings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate across model variants ##\n",
    "for model_variant in model_type_list:\n",
    "    print(\"Variant: %s\"%model_variant)\n",
    "    ## Variant Start Time ##\n",
    "    variant_start = datetime.now()\n",
    "    \n",
    "    ## SHAP Results dictionary path ##\n",
    "    output_path = results_folder+'FeatureRanks_'+model_variant+'.pkl'\n",
    "\n",
    "    ## Check if Feature Ranks already exists for model ##\n",
    "    # if(not os.path.exists( output_path ) or not skip_complete):\n",
    "        ## Load Model Hyperparameters from HPTune dataframe ##\n",
    "        # hyperparameters_of_interest = hptune_df[(hptune_df['penultimate_activation_type']==model_variant) & \n",
    "                                                # (hptune_df['optimized_model']==True) & \n",
    "                                                # (hptune_df['outcome_variable']==outcome_column)]\n",
    "    ## Setup Hyperparameter Values ##\n",
    "    dropout1_p = 0.0 #hyperparameters_of_interest['dropout1_p'].values[0]\n",
    "    dropout2_p = 0.0 #hyperparameters_of_interest['dropout2_p'].values[0]\n",
    "    dropout3_p = 0.0 #hyperparameters_of_interest['dropout3_p'].values[0]\n",
    "    clustering_neurons = 128 #hyperparameters_of_interest['clustering_neurons'].values[0]\n",
    "    learning_rate = 1e-4 #hyperparameters_of_interest['learning_rate'].values[0]\n",
    "    outcome_variable = 'death90+vent'\n",
    "\n",
    "    ## Model Name ##\n",
    "    model_name = 'ALLFEATURES_ACTIVATION={}_CN={}_D1P={}_D2P={}_D3P={}_LR={}_OUTCOME={}'.format(model_variant, clustering_neurons, dropout1_p, dropout2_p, dropout3_p, learning_rate, outcome_variable)\n",
    "    ## Model Load ##\n",
    "    model = DeepLearningArchitecture(dropout1_p=dropout1_p, dropout2_p=dropout2_p, dropout3_p=dropout3_p,\n",
    "                                                clustering_neurons=clustering_neurons,\n",
    "                                                penultimate_activation_type=model_variant)\n",
    "    model.load_state_dict(torch.load('{}{}_checkpoint.pth'.format(models_folder, model_name)))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    ## Set SHAP Results ##\n",
    "    f_rankings_dict[model_variant] = {}\n",
    "    f_rankings_dict[model_variant]['ranks'], f_rankings_dict[model_variant]['shap_values'] = model_xai(model, x_train, x_train, \n",
    "                                                                                                        model_type=model_variant,\n",
    "                                                                                                        feature_names=np.array(x_train.columns),\n",
    "                                                                                                        top_n_features=top_n_features,\n",
    "                                                                                                        savefigpath=figures_folder,\n",
    "                                                                                                        random_state=random_state,\n",
    "                                                                                                        device=device)\n",
    "\n",
    "    ## Save Dictionary ##\n",
    "    with open(output_path, 'wb') as fh:\n",
    "        pickle.dump(f_rankings_dict[model_variant], fh)\n",
    "# else:\n",
    "    #     print('Exists: %s'% model_variant)\n",
    "        \n",
    "    ## Variant Time (minutes) ##\n",
    "    variant_time= (datetime.now()-variant_start).total_seconds() / 60.\n",
    "    print(\"Variant Time (mins): {:.2f}\".format(variant_time) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d467bfd867aebb3d3ad962bbea3860471efe3f8ba2e781345e08ddf592cac4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
